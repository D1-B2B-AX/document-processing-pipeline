from fastapi import APIRouter, UploadFile, File, HTTPException
from pptx import Presentation
from openai import OpenAI
import io
import os

client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))
router = APIRouter()

# =========================================================
# [ì„¤ì •] ì œì™¸ í‚¤ì›Œë“œ
# =========================================================
EXCLUDE_KEYWORDS = [
    "ìœ ì‚¬", "ì‚¬ë¡€", "ì‹¤ì ", "reference", "case", "history", "result",
    "ê°•ì‚¬í”„ë¡œí•„", "ìˆ˜í–‰ì‹¤ì ", "ì œì•ˆì‚¬", "íšŒì‚¬ì†Œê°œ", "appendix", "ë³„ì²¨"
]

# =========================================================
# [í•µì‹¬] ë²„ì „ì„ íƒ€ì§€ ì•ŠëŠ” 'ë¬´ì¡°ê±´ ì¬ê·€ íƒìƒ‰' (Duck Typing)
# =========================================================
def get_text_from_shape_recursive(shape):
    """
    ëª¨ì–‘(Type)ì„ ë”°ì§€ì§€ ì•Šê³ , í…ìŠ¤íŠ¸ë‚˜ í•˜ìœ„ ë„í˜•ì´ ìˆìœ¼ë©´ ë¬´ì¡°ê±´ ì¶”ì¶œí•©ë‹ˆë‹¤.
    (ë¼ì´ë¸ŒëŸ¬ë¦¬ ë²„ì „ì´ ë‹¬ë¼ë„ 100% ë™ì‘í•¨)
    """
    text_parts = []

    try:
        # 1. í…ìŠ¤íŠ¸ê°€ ìˆëŠ”ê°€? (TextFrame)
        if hasattr(shape, "text") and shape.text and shape.text.strip():
            text_parts.append(shape.text.strip())

        # 2. í‘œì¸ê°€? (Table)
        if hasattr(shape, "table") and shape.table:
            for row in shape.table.rows:
                row_cells = [c.text.replace('\n', ' ').strip() for c in row.cells if c.text.strip()]
                if row_cells:
                    text_parts.append(f"| {' | '.join(row_cells)} |")

        # 3. ìì‹ì„ ê°€ì§„ ì»¨í…Œì´ë„ˆ(ê·¸ë£¹)ì¸ê°€? 
        # (MSO_SHAPE_TYPE í™•ì¸ ëŒ€ì‹ , shapes ì†ì„±ì´ ìˆëŠ”ì§€ë¡œ íŒë‹¨ -> ë²„ì „ í˜¸í™˜ì„± í•´ê²°)
        if hasattr(shape, "shapes"):
            for child in shape.shapes:
                text_parts.extend(get_text_from_shape_recursive(child))
                
    except Exception as e:
        # íŠ¹ì • ë„í˜•ì—ì„œ ì—ëŸ¬ê°€ ë‚˜ë„ ë©ˆì¶”ì§€ ì•Šê³  ë¬´ì‹œ
        print(f"âš ï¸ ë„í˜• ì²˜ë¦¬ ì¤‘ ìŠ¤í‚µ: {e}")
        pass

    return text_parts

def extract_all_text(slide):
    all_texts = []
    
    # ì œëª© ì²˜ë¦¬
    try:
        if slide.shapes.title and slide.shapes.title.text.strip():
            all_texts.append(f"### {slide.shapes.title.text.strip()}")
    except:
        pass # ì œëª© ì—†ìœ¼ë©´ íŒ¨ìŠ¤

    # ë³¸ë¬¸ ì²˜ë¦¬
    for shape in slide.shapes:
        # ì œëª© ê°ì²´ëŠ” ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•´ ê±´ë„ˆëœ€
        try:
            if slide.shapes.title and shape == slide.shapes.title:
                continue
        except:
            pass
            
        # ì¬ê·€ ì¶”ì¶œ ì‹¤í–‰
        all_texts.extend(get_text_from_shape_recursive(shape))
        
    return "\n".join(all_texts)

# =========================================================
# [LLM] ë§ˆí¬ë‹¤ìš´ ë³€í™˜
# =========================================================
def generate_markdown(filename, text_content):
    if len(text_content) < 50: return None

    # ë„ˆë¬´ ê¸¸ë©´ ìë¥´ê¸° (í† í° ë¹„ìš© ì ˆì•½ ë° ì—ëŸ¬ ë°©ì§€)
    safe_text = text_content[:25000]

    prompt = f"""
    ë‹¹ì‹ ì€ 'ê¸°ì—… êµìœ¡ ì œì•ˆì„œ ë¶„ì„ ì „ë¬¸ê°€'ì…ë‹ˆë‹¤.
    ì•„ë˜ í…ìŠ¤íŠ¸ëŠ” PPTì—ì„œ ì¶”ì¶œí•œ ì»¤ë¦¬í˜ëŸ¼ ë‚´ìš©ì…ë‹ˆë‹¤.
    
    [ì§€ì‹œì‚¬í•­]
    1. ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ **RAGìš© Markdown**ìœ¼ë¡œ ì •ë¦¬í•´ì¤˜.
    2. ë¬¸ì„œ ìƒë‹¨ì— `> **Keywords**: ...` í•„ìˆ˜ í¬í•¨.
    3. **ì‹œê°„ ì •ë³´(1H, 2H, 09:00~) ì ˆëŒ€ ì‚­ì œ ê¸ˆì§€.**
    4. í‘œ í˜•ì‹ì€ Markdown Tableë¡œ ë³€í™˜.
    5. ì¡ë‹´ ì—†ì´ ê²°ê³¼ë§Œ ì¶œë ¥.
    
    [íŒŒì¼ëª…] {filename}
    [ë‚´ìš©]
    {safe_text}
    """

    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            temperature=0
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        print(f"âŒ LLM Error: {e}")
        return None

# =========================================================
# [Endpoint]
# =========================================================
@router.post("/parse")
async def parse_curriculum(file: UploadFile = File(...)):
    print(f"\nğŸš€ [Duck Typing Fix] íŒŒì¼ ì²˜ë¦¬ ì‹œì‘: {file.filename}")
    
    content = await file.read()
    
    try:
        prs = Presentation(io.BytesIO(content))
    except Exception as e:
        raise HTTPException(status_code=400, detail="Invalid PPTX file")

    # í…ìŠ¤íŠ¸ ì¶”ì¶œ (í•„í„°ë§ ì—†ì´ ì „ì²´ ìˆ˜ì§‘)
    full_text_list = []
    
    for i, slide in enumerate(prs.slides):
        text = extract_all_text(slide)
        
        # ê°„ë‹¨í•œ ì œì™¸ í‚¤ì›Œë“œ ì²´í¬
        is_exclude = False
        for key in EXCLUDE_KEYWORDS:
            if key in text: 
                is_exclude = True
                break
        
        if not is_exclude and len(text.strip()) > 5:
            full_text_list.append(f"\n--- [Slide {i+1}] ---\n{text}")

    combined_text = "\n".join(full_text_list)
    print(f"ğŸ“ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(combined_text)}ì")

    # ê²°ê³¼ ìƒì„±
    results = []
    
    # í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ë¬´ì¡°ê±´ ë³€í™˜ ì‹œë„
    if len(combined_text) > 30:
        md_content = generate_markdown(file.filename, combined_text)
        
        if md_content:
            base_name = os.path.splitext(file.filename)[0]
            results.append({
                "course_index": 1,
                "suggested_filename": f"{base_name}_Parsed.md",
                "markdown": md_content
            })
    else:
        print("ğŸš¨ ì—¬ì „íˆ í…ìŠ¤íŠ¸ê°€ 0ì…ë‹ˆë‹¤. ì´ë¯¸ì§€ íŒŒì¼ì´ê±°ë‚˜ ì•”í˜¸í™”ëœ íŒŒì¼ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    return {
        "domain": "curriculum",
        "original_filename": file.filename,
        "parsed_courses": results,
        "count": len(results)
    }